{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import random\n",
    "import string\n",
    "import uuid\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import shared functions\n",
    "sys.path.append('..\\..')\n",
    "from IPM_Shared_Code_public.Python.utils import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config('c:\\Projects\\config.ini')\n",
    "\n",
    "driver = config['srv']['driver']\n",
    "gis_server = config['srv']['server']\n",
    "pip_server = config['srv']['pip']\n",
    "gis = config['db']['parksgis']\n",
    "pip = config['db']['pip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_string = 'Driver={' + driver + '};Server=' + pip_server +';Database=' + pip + ';Trusted_Connection=Yes;'\n",
    "params = urllib.parse.quote_plus(con_string)\n",
    "pip_engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_string = 'Driver={' + driver + '};Server=' + gis_server +';Database=' + gis + ';Trusted_Connection=Yes;'\n",
    "params = urllib.parse.quote_plus(con_string)\n",
    "gis_engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the prop id lookup field dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the dict of dicts that contains the feature classes and the translated column names\n",
    "field_lookup = {'property_evw': {'propnum': 'gispropnum',\n",
    "                                 'prop id': 'gispropnum', \n",
    "                                 'borough': 'department',\n",
    "                                 'ampsdistrict': 'department',\n",
    "                                 'prop name': 'signname',\n",
    "                                 'site name': 'signname',\n",
    "                                 'prop location': 'location',\n",
    "                                 'site location': 'location',\n",
    "                                 'acres': 'acres', \n",
    "                                 'jurisdiction': 'jurisdiction', \n",
    "                                 'typecategory': 'typecategory', \n",
    "                                 'featurestatus':'featurestatus', \n",
    "                                 'gisobjid':'gisobjid'}, \n",
    "                 'playground_evw': {'propnum': 'parentid', \n",
    "                                    'prop id': 'omppropid', \n",
    "                                    'borough': 'department',\n",
    "                                    'ampsdistrict': 'department',\n",
    "                                    'site name': 'signname', \n",
    "                                    'site location': 'location', \n",
    "                                    'acres': 'acres', \n",
    "                                    'jurisdiction': 'jurisdiction', \n",
    "                                    'featurestatus':'featurestatus', \n",
    "                                    'gisobjid':'gisobjid'},  \n",
    "                 'zone_evw': {'propnum': 'parentid', \n",
    "                              'prop id': 'omppropid', \n",
    "                              'borough': 'department',\n",
    "                              'ampsdistrict': 'department',\n",
    "                              'site name': 'sitename', \n",
    "                              'site location': 'location', \n",
    "                              'acres': 'acres', \n",
    "                              'jurisdiction': 'jurisdiction', \n",
    "                              'featurestatus':'featurestatus', \n",
    "                              'gisobjid':'gisobjid'}, \n",
    "\n",
    "                 'unmapped_gisallsites_evw': {'propnum': 'gispropnum',\n",
    "                                              'prop id': 'omppropid', \n",
    "                                              'borough': 'department',\n",
    "                                              'ampsdistrict': 'department',\n",
    "                                              'site name': 'name',\n",
    "                                              'site location': 'location',\n",
    "                                              'acres': 'acres', \n",
    "                                              'jurisdiction': 'jurisdiction'},\n",
    "                 'schoolyard_to_playground_evw': {'propnum': 'gispropnum',\n",
    "                                                  'prop id': 'gispropnum', \n",
    "                                                  'borough': 'department',\n",
    "                                                  'ampsdistrict': 'department',\n",
    "                                                  'prop name': 'signname',\n",
    "                                                  'site name': 'signname',\n",
    "                                                  'prop location': 'location',\n",
    "                                                  'site location': 'location',\n",
    "                                                  'acres': 'acres', \n",
    "                                                  'jurisdiction': 'jurisdiction', \n",
    "                                                  'featurestatus':'featurestatus'},\n",
    "                 'greenstreet_evw': {'propnum': 'omppropid', \n",
    "                                     'prop id': 'omppropid', \n",
    "                                     'borough': 'department',\n",
    "                                     'ampsdistrict': 'department',\n",
    "                                     'site name': 'sitename', \n",
    "                                     'site location': 'location', \n",
    "                                     'acres': 'acres', \n",
    "                                     'jurisdiction': 'jurisdiction', \n",
    "                                     'featurestatus':'featurestatus', \n",
    "                                     'gisobjid':'gisobjid'},\n",
    "                 'golfcourse_evw': {'propnum': 'gispropnum', \n",
    "                                    'prop id': 'omppropid', \n",
    "                                    'borough': 'department',\n",
    "                                    'ampsdistrict': 'department',\n",
    "                                    'site name': 'name', \n",
    "                                    'site location': 'location', \n",
    "                                    'acres': 'acres', \n",
    "                                    'jurisdiction': 'jurisdiction', \n",
    "                                    'featurestatus':'featurestatus', \n",
    "                                    'gisobjid':'gisobjid'},\n",
    "                 'restrictivedeclarationsite_evw': {'propnum': 'gispropnum',\n",
    "                                                    'prop id': 'gispropnum', \n",
    "                                                    'borough': 'department',\n",
    "                                                    'ampsdistrict': 'department',\n",
    "                                                    'prop name': 'signname',\n",
    "                                                    'site name': 'signname',\n",
    "                                                    'prop location': 'location',\n",
    "                                                    'site location': 'location',\n",
    "                                                    'acres': 'acres', \n",
    "                                                    'jurisdiction': 'jurisdiction', \n",
    "                                                    'featurestatus':'featurestatus'}, \n",
    "                 'structure_evw': {'propnum': 'gispropnum',\n",
    "                                   'prop id': 'omppropid', \n",
    "                                   'borough': 'department',\n",
    "                                   'ampsdistrict': 'department',\n",
    "                                   'prop name': 'description',\n",
    "                                   'site name': 'description',\n",
    "                                   'prop location': 'location',\n",
    "                                   'site location': 'location',\n",
    "                                   'jurisdiction': 'jurisdiction',  \n",
    "                                   'featurestatus':'featurestatus', \n",
    "                                   'gisobjid':'gisobjid'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a dict of source feature classes that map to the sourcefc value\n",
    "sourcefc_lookup = {'property_evw': 'Property', \n",
    "                   'playground_evw': 'Playground', \n",
    "                   'zone_evw': 'Zone', \n",
    "                   'unmapped_gisallsites_evw': 'Unmapped',\n",
    "                   'schoolyard_to_playground_evw': 'Schoolyard To Playground',\n",
    "                   'greenstreet_evw': 'Greenstreet',\n",
    "                   'golfcourse_evw': 'GolfCourse',\n",
    "                   'restrictivedeclarationsite_evw': 'RestrictiveDeclarationSite',\n",
    "                   'structure_evw': 'Structure'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_lookup_as = {f: ['['+ i[1] + '] as ' + '['+ i[0] + ']' for i in field_lookup[f].items()] for f in sourcefc_lookup }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original GIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the tables that will be queried and interacted with\n",
    "gis_tables = ['property_evw', 'playground_evw', 'zone_evw', 'unmapped_gisallsites_evw', \n",
    "              'schoolyard_to_playground_evw', 'greenstreet_evw', 'golfcourse_evw', \n",
    "              'restrictivedeclarationsite_evw', 'structure_evw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the list of SQL Queries\n",
    "gis_sql_list = [\"select objectid, {}, '{}' as sourcefc from parksgis.dpr.{}\"\n",
    "                .format(' ,'.join(field_lookup_as[t]), sourcefc_lookup[t], t) \n",
    "                        for t in gis_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with sources and dataframes that contain the original data\n",
    "gis_df_list = {s: pd.read_sql(con = gis_engine, sql = q) for q, s in zip(gis_sql_list, gis_tables)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute all the stored procedures before starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_delete_sql = '''begin transaction\n",
    "                       truncate table accessnewpip.dbo.tbl_temp_ref_allsites\n",
    "                       \n",
    "                       truncate table accessnewpip.dbo.tbl_ref_allsites_nosync\n",
    "                       \n",
    "                       truncate table accessnewpip.dbo.tbl_ref_allsites_audit\n",
    "                       \n",
    "                       truncate table accessnewpip.dbo.tbl_pip_allsites\n",
    "                       \n",
    "                       truncate table accessnewpip.dbo.tbl_pip_allsites_audit\n",
    "                       \n",
    "                       delete \n",
    "                       from accessnewpip.dbo.tbl_ref_allsites\n",
    "                   commit'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_sql = ['exec accessnewpip.dbo.usp_m_tbl_temp_ref_allsites', 'exec accessnewpip.dbo.usp_m_tbl_ref_allsites',\n",
    "          'exec accessnewpip.dbo.usp_m_tbl_ref_allsites_nosync', 'exec accessnewpip.dbo.usp_m_tbl_pip_allsites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_con = pip_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through and execute the update queries\n",
    "for q in [db_delete_sql] + db_sql:\n",
    "    pip_con.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original PIP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the tables that will be queried and interacted with\n",
    "pip_tables = ['tbl_ref_allsites', 'tbl_ref_allsites_audit', 'tbl_ref_allsites_nosync', 'tbl_pip_allsites', \n",
    "              'vw_pip_sync', 'allsites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the list of SQL Queries\n",
    "pip_sql_list = ['select * from accessnewpip.dbo.'+ t for t in pip_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of dataframes with the original dat\n",
    "pip_df_list = {s: pd.read_sql(con = pip_engine, sql = q) for q, s in zip(pip_sql_list, pip_tables)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select distinct [prop id] from accessnewpip.dbo.vw_pip_sync'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_sync_view = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_propid = list(pip_sync_view['prop id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the lengths of the GIS datasets\n",
    "gis_df_lens = {g: len(gis_df_list[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_rows(x):\n",
    "    if x > 35:\n",
    "        n = math.ceil(x * random.uniform(0.001, 0.01))* 2\n",
    "    else:\n",
    "        n = math.floor(x/3) * 2\n",
    "        \n",
    "    return n   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate a percentage of rows that will be used \n",
    "n_rows = {g: get_n_rows(gis_df_lens[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_dfs_update_delete = {g: gis_df_list[g].copy().head(n_rows[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_dfs_update = {g: gis_dfs_update_delete[g].copy().head(math.ceil(n_rows[g]/2)) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_dfs_delete = {g: gis_dfs_update_delete[g].copy().tail(math.floor(n_rows[g]/2)) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_dfs_insert = {g: gis_df_list[g].copy().tail(math.ceil(n_rows[g]/2)) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform DML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_props = {g: list(gis_dfs_delete[g]['objectid']) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_list = {g: ','.join(f\"'{p}'\" for p in list(list_props[g])) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the common where clause using the prop id field lookup for each source GIS feature class\n",
    "where = {f: str(r\"where objectid in({})\").format(where_list[f]) for f in field_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through the GIS datasets, drop the _evw and create the queries that perform the deletes\n",
    "sql = ['delete from parksgis.dpr.{} {}'.format(g.replace('_evw', ''), where[g]) for g in gis_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_con = gis_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through and execute the delete queries\n",
    "for q in sql:\n",
    "    gis_con.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of dataframes with the data after deletes, notably all dfs should be empty\n",
    "gis_df_post_delete = {g: gis_df_list[g][gis_df_list[g]['prop id'].isin(list_props[g])] for g in gis_tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_col = 'site location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_val = 'Testing Updates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_props = {g: list(gis_dfs_update[g]['objectid']) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_list = {g: ','.join(f\"'{p}'\" for p in list(list_props[g])) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the common where clause using the prop id field lookup for each source GIS feature class\n",
    "where = {f: str(r\"where objectid in({})\").format(where_list[f]) for f in field_lookup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_value = {g: str(r\"[{}] = '{}'\").format(field_lookup[g][update_col], update_val) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through the GIS datasets, drop the _evw and perform the deletes\n",
    "sql = ['update parksgis.dpr.{} set {}  {}'.format(g.replace('_evw', ''), set_value[g], where[g]) for g in gis_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through and execute the update queries\n",
    "for q in sql:\n",
    "    gis_con.execute(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Non-Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to generate prop ids\n",
    "def gen_propid(sourcefc):\n",
    "    boros = ['B','Q','M','R','X']\n",
    "\n",
    "    boro = boros[random.randint(0,len(boros) - 1)]\n",
    "    \n",
    "    num = f'{random.randint(0, 999):03}'\n",
    "    \n",
    "    letters = list(string.ascii_uppercase)\n",
    "    \n",
    "    suffixes = ['', letters[random.randint(0,len(letters) - 1)]]\n",
    "    \n",
    "    suffix = suffixes[random.randint(0,len(suffixes) - 1)]\n",
    "    \n",
    "    suffix_num = f'{random.randint(0, 99):02}'\n",
    "    \n",
    "    if sourcefc == 'zone_evw':\n",
    "        propid = boro + num + suffix + '-ZN' + suffix_num\n",
    "        \n",
    "    elif sourcefc == 'playground_evw':\n",
    "        propid = boro + num + suffix + '-' + suffix_num\n",
    "        \n",
    "    elif sourcefc == 'greenstreet_evw':     \n",
    "        propid = boro + 'Z' + num + suffix\n",
    "        \n",
    "    else:\n",
    "        propid = boro + num + suffix\n",
    "        \n",
    "    if propid not in existing_propid:\n",
    "        existing_propid.append(propid)\n",
    "        return propid\n",
    "    \n",
    "    else:\n",
    "        return(gen_propid(sourcefc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(sourcefc):\n",
    "    for k, v in field_lookup[sourcefc].items():\n",
    "        if k == 'prop id':\n",
    "            return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cols = {g:[k for k, v in field_lookup[g].items() if v in get_value(g)] for g in gis_tables }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gis_tables:\n",
    "    \n",
    "    #Take the existing max objectid and add that value to the current objectid\n",
    "    objectid = gis_df_list[g].copy()['objectid'].max()\n",
    "    gis_dfs_insert[g]['objectid'] = gis_dfs_insert[g].apply(lambda x: x['objectid'] + objectid, axis = 1)\n",
    "    \n",
    "    #Add a globalid column because it's required\n",
    "    gis_dfs_insert[g]['globalid'] = gis_dfs_insert[g].apply(lambda x: str(uuid.uuid4()), axis = 1)\n",
    "    \n",
    "    #Generate the prop ids for all relevant columns\n",
    "    for c in apply_cols[g]:\n",
    "        gis_dfs_insert[g][c] = gis_dfs_insert[g].apply(lambda x: gen_propid(g), axis = 1)\n",
    "     \n",
    "    #Rename the columns to the original names\n",
    "    gis_dfs_insert[g].rename(columns = field_lookup[g], inplace = True)\n",
    "    \n",
    "    #Remove duplicate columns and drop the sourcefc column\n",
    "    gis_dfs_insert[g] = gis_dfs_insert[g].loc[:,~gis_dfs_insert[g].columns.duplicated()].drop(columns = ['sourcefc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gis_tables:\n",
    "    fc = g.replace('_evw', '')\n",
    "    gis_dfs_insert[g].to_sql(fc, gis_con, schema = 'dpr', if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the PIP Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through and execute the update queries\n",
    "with pip_engine.begin() as pip_con:\n",
    "    for q in db_sql:\n",
    "        pip_con.execute(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the PIP and GIS Tables after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of dataframes with the original dat\n",
    "pip_df_list_after = {s: pd.read_sql(con = pip_engine, sql = q) for q, s in zip(pip_sql_list, pip_tables)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with sources and dataframes that contain the original data\n",
    "gis_df_list_after = {s: pd.read_sql(con = gis_engine, sql = q) for q, s in zip(gis_sql_list, gis_tables)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct the Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the before and after dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_df_update_ck = {g: gis_dfs_update[g].merge(gis_df_list_after[g], how = 'left', on = 'objectid', indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_df_delete_ck = {g: gis_dfs_delete[g].merge(gis_df_list_after[g], how = 'left', on = 'objectid', indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_df_insert_ck = {g: gis_dfs_insert[g].merge(gis_df_list_after[g], how = 'left', left_on = field_lookup[g]['prop id'], right_on = 'prop id', indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate that the row count of the deleted records matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The length of the records that are only in the deleted df (left_only) should be equal to the number of records in the delted df.\n",
    "gis_delete_valid = {g: len(gis_df_delete_ck[g][gis_df_delete_ck[g]['_merge'] == 'left_only']) == len(gis_dfs_delete[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Deletes in GIS evws' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_insert_valid = {g: len(gis_df_insert_ck[g][gis_df_insert_ck[g]['_merge'] == 'both']) == len(gis_dfs_insert[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Inserts into GIS evws' : all(v == True for v in gis_insert_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_update_valid = {g: len(gis_df_update_ck[g][gis_df_update_ck[g]['_merge'] == 'both']) == len(gis_dfs_update[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Updates into GIS evws' : all(v == True for v in gis_update_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_update_valid2 = {g: len(gis_df_update_ck[g][gis_df_update_ck[g][update_col + '_y'] == update_val]) == len(gis_dfs_update[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Updates values into GIS evws' : all(v == True for v in gis_update_valid2.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the datetime column to date only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_date = datetime.utcnow().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_list_after['tbl_ref_allsites']['created_date'] = pip_df_list_after['tbl_ref_allsites'].apply(lambda x: x['created_date'].strftime('%Y-%m-%d'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_list_after['tbl_pip_allsites']['created_date'] = pip_df_list_after['tbl_pip_allsites'].apply(lambda x: x['created_date'].strftime('%Y-%m-%d'), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the validation with Allsites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_update_ck = {g: gis_dfs_update[g].merge(pip_df_list_after['tbl_ref_allsites'][pip_df_list_after['tbl_ref_allsites']['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = ['prop id'], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_update_audit_ck = {g: gis_dfs_update[g].merge(pip_df_list_after['tbl_ref_allsites_audit'][pip_df_list_after['tbl_ref_allsites_audit']['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = ['prop id'], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_delete_ck = {g: gis_dfs_delete[g].merge(pip_df_list_after['tbl_ref_allsites'][pip_df_list_after['tbl_ref_allsites']['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = ['prop id'], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_insert_ck = {g: gis_dfs_insert[g].merge(pip_df_list_after['tbl_ref_allsites'][pip_df_list_after['tbl_ref_allsites']['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = [field_lookup[g]['prop id']], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_insert_ck2 = {g: gis_dfs_insert[g].merge(pip_df_list_after['tbl_pip_allsites'], how = 'left', left_on = [field_lookup[g]['prop id']], right_on = ['prop id'], indicator = True, suffixes = (None, '_y')) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the validity for all the PIP Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_update_valid = {g: len(pip_df_update_ck[g][(pip_df_update_ck[g]['_merge'] == 'both') & (pip_df_update_ck[g][update_col] == update_val)]) == len(gis_dfs_update[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Updates with values in tbl_ref_allsites' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_update_audit_valid = {g: len(pip_df_update_audit_ck[g][(pip_df_update_audit_ck[g]['_merge'] == 'both') & (pip_df_update_audit_ck[g]['created_date'] == ck_date)]) == len(gis_dfs_update[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Updates in tbl_ref_allsites_audit' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_delete_valid = {g: len(pip_df_delete_ck[g][(pip_df_delete_ck[g]['_merge'] == 'both') & (pip_df_delete_ck[g]['gis_deleted'] == 1)]) == len(gis_dfs_delete[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Deletes tbl_ref_allsites with flag' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_insert_valid = {g: len(pip_df_insert_ck[g][(pip_df_insert_ck[g]['_merge'] == 'both') & (pip_df_insert_ck[g]['created_date'] == ck_date)]) == len(gis_dfs_insert[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Inserts into tbl_ref_allsites' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_df_insert_valid2 = {g: len(pip_df_insert_ck2[g][(pip_df_insert_ck2[g]['_merge'] == 'both') & (pip_df_insert_ck[g]['created_date'] == ck_date)]) == len(gis_dfs_insert[g]) for g in gis_tables if g not in 'structure_evw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Inserts into tbl_pip_allsites, except structures' : all(v == True for v in gis_delete_valid.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Duplicates and Check tbl_ref_allsites_nosync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from accessnewpip.dbo.tbl_ref_allsites_nosync'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_before = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gispropnum'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_lookup['property_evw']['prop id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_before_ck = {g: gis_dfs_insert[g].merge(pip_allsites_nosync_before[pip_allsites_nosync_before['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = field_lookup[g]['prop id'], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_before_valid = {g: len(pip_allsites_nosync_before_ck[g][pip_allsites_nosync_before_ck[g]['_merge'] == 'left_only']) == len(gis_dfs_insert[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of Inserts, none appear in tbl_ref_allsites_nosync' : all(v == True for v in pip_allsites_nosync_before_valid.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gis_tables:\n",
    "    #Take the existing max objectid and add that value to the current objectid\n",
    "    objectid = gis_dfs_insert[g].copy()['objectid'].max()\n",
    "    gis_dfs_insert[g]['objectid'] = gis_dfs_insert[g].apply(lambda x: x['objectid'] + objectid, axis = 1)\n",
    "    \n",
    "    #Add a globalid column because it's required\n",
    "    gis_dfs_insert[g]['globalid'] = gis_dfs_insert[g].apply(lambda x: str(uuid.uuid4()), axis = 1)\n",
    "    \n",
    "    fc = g.replace('_evw', '')\n",
    "    gis_dfs_insert[g].to_sql(fc, gis_con, schema = 'dpr', if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through and execute the update queries\n",
    "with pip_engine.begin() as pip_con:\n",
    "    for q in db_sql:\n",
    "        pip_con.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_after = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_after_ck = {g: gis_dfs_insert[g].merge(pip_allsites_nosync_after[pip_allsites_nosync_after['sourcefc'] == sourcefc_lookup[g]], how = 'left', left_on = field_lookup[g]['prop id'], right_on = ['Prop ID'], indicator = True, suffixes = (None, '_y')) for g in gis_tables} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_nosync_after_valid = {g: len(pip_allsites_nosync_after_ck[g][pip_allsites_nosync_after_ck[g]['_merge'] == 'both']) == len(gis_dfs_insert[g]) for g in gis_tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validation of duplicate Inserts, duplicate records appear in tbl_ref_allsites_nosync' : all(v == True for v in pip_allsites_nosync_after_valid.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test auditing in tbl_pip_allsites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from accessnewpip.dbo.tbl_pip_allsites where category in('Large Park', 'Small Park')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the original data from the tbl_pip_allsites table\n",
    "pip_allsites_before = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = get_n_rows(len(pip_allsites_before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_updates = pip_allsites_before.head(n_rows).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_deletes = pip_allsites_before.tail(n_rows).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_props = list(pip_allsites_updates['prop id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_list = ','.join(f\"'{p}'\" for p in list(list_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through the GIS datasets, drop the _evw and perform the deletes\n",
    "sql = 'update accessnewpip.dbo.tbl_pip_allsites set rated = 1 where [prop id] in({})'.format(where_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pip_engine.begin() as pip_con:\n",
    "    pip_con.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_props = list(pip_allsites_deletes['prop id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_list = ','.join(f\"'{p}'\" for p in list(list_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through the GIS datasets, drop the _evw and perform the deletes\n",
    "sql = 'delete from accessnewpip.dbo.tbl_pip_allsites where [prop id] in({})'.format(where_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0xeefa288>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pip_engine.begin() as pip_con:\n",
    "    pip_con.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from accessnewpip.dbo.tbl_pip_allsites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the updated/deleted data from the tbl_pip_allsites table\n",
    "pip_allsites_after = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from accessnewpip.dbo.tbl_pip_allsites_audit where cast(updated_date as date) = '{}'\".format(ck_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the updated/deleted data from the tbl_pip_allsites table\n",
    "pip_allsites_audit_after = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_delete = pip_allsites_audit_after[pip_allsites_audit_after['dml_verb'] == 'D'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_delete_ck = pip_allsites_deletes.merge(pip_allsites_audit_after_delete, how = 'left', on = 'prop id', indicator = True, suffixes = (None, '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validated that deletes are audited in tbl_pip_allsites_audit': len(pip_allsites_audit_after_delete_ck[pip_allsites_audit_after_delete_ck['_merge'] == 'both']) == len(pip_allsites_deletes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_after_delete_ck2 = pip_allsites_deletes.merge(pip_allsites_after, how = 'left', on = 'prop id', indicator = True, suffixes = (None, '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validated that deletes are gone from tbl_pip_allsites': len(pip_allsites_after_delete_ck2[pip_allsites_after_delete_ck2['_merge'] == 'left_only']) == len(pip_allsites_deletes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_update = pip_allsites_audit_after[pip_allsites_audit_after['dml_verb'] == 'U'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_update_ck = pip_allsites_updates.merge(pip_allsites_audit_after_update, how = 'left', on = 'prop id', indicator = True, suffixes = (None, '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validated that updates are audited in tbl_pip_allsites audit': len(pip_allsites_audit_after_update_ck[pip_allsites_audit_after_update_ck['_merge'] == 'both']) == len(pip_allsites_updates)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_update.drop(columns = ['pip_allsites_audit_id', 'updated_date', 'updated_user', 'dml_verb'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_audit_after_update_ck2 = pd.concat([pip_allsites_audit_after_update, pip_allsites_updates]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validated that original records values are recorded in tbl_pip_allsites_audit': len(pip_allsites_audit_after_update_ck2) == len(pip_allsites_updates)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring back the deletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pip_engine.begin() as pip_con:\n",
    "    pip_con.execute('exec accessnewpip.dbo.usp_m_tbl_pip_allsites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from accessnewpip.dbo.tbl_pip_allsites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the updated/deleted data from the tbl_pip_allsites table\n",
    "pip_allsites_after_newsync = pd.read_sql(con = pip_engine, sql = sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_allsites_after_delete_ck3 = pip_allsites_deletes.merge(pip_allsites_after_newsync, how = 'left', on = 'prop id', indicator = True, suffixes = (None, '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.append({'Validated that the sync inserted the delete records': len(pip_allsites_after_delete_ck3[pip_allsites_after_delete_ck3['_merge'] == 'both']) == len(pip_allsites_deletes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Validation of Deletes in GIS evws': True},\n",
       " {'Validation of Inserts into GIS evws': True},\n",
       " {'Validation of Updates into GIS evws': True},\n",
       " {'Validation of Updates values into GIS evws': True},\n",
       " {'Validation of Updates with values in tbl_ref_allsites': True},\n",
       " {'Validation of Updates in tbl_ref_allsites_audit': True},\n",
       " {'Validation of Deletes tbl_ref_allsites with flag': True},\n",
       " {'Validation of Inserts into tbl_ref_allsites': True},\n",
       " {'Validation of Inserts into tbl_pip_allsites, except structures': True},\n",
       " {'Validation of Inserts, none appear in tbl_ref_allsites_nosync': True},\n",
       " {'Validation of duplicate Inserts, duplicate records appear in tbl_ref_allsites_nosync': True},\n",
       " {'Validated that deletes are audited in tbl_pip_allsites_audit': True},\n",
       " {'Validated that deletes are gone from tbl_pip_allsites': True},\n",
       " {'Validated that updates are audited in tbl_pip_allsites audit': True},\n",
       " {'Validated that original records values are recorded in tbl_pip_allsites_audit': True},\n",
       " {'Validated that the sync inserted the delete records': True}]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
